{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating a GARCH(1,1) from A to Z\n",
    "\n",
    "$Gilles \\space HACHEME$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Garch(1,1)}  :  \\epsilon_{t} = v_{t} \\sqrt{h_{t}}\\\\\n",
    "h_{t} = a_{0} + a_{1} \\epsilon_{t-1}^2 + b_{1}h_{t-1} \\\\\n",
    "With \\space v_{t} \\sim  \\mathcal{N}(0, h_{t})\n",
    "\t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating $h_{t}$ until order t, we get : \n",
    "\n",
    "$h_{t} = a_{0} \\frac{1-b_{1}^t}{1 - b_{1}} + a_{1} \\sum_{i=0}^{t-1} b_{1}^i \\epsilon_{t-1-i}^2 + b_{1}^t h_{0}$\n",
    "\n",
    "We didn't use here any stationarity condition. And for this tutorial, we will suppose $h_{0} = 0$ \n",
    "\n",
    "For memory we would use in the stationary assumption case : \n",
    "\n",
    "$h_{t} =  \\frac{a_{0}}{1 - b_{1}} + a_{1} \\sum_{i=0}^{t-1} b_{1}^i \\epsilon_{t-1-i}^2$\n",
    "\n",
    "For t sufficiently large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Simulating some values for epsilon square\n",
    "Epsquare_t1=np.array([2,4,6,9,0,4,7])\n",
    "T=len(Epsquare_t1)  #Number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\textbf{Computing the Likelihood function} : \\\\\\\\\n",
    "    L(\\theta) = \\prod_{t=1}^{T} \\frac{1}{2\\pi h_{t}} \\exp{\\frac{-\\epsilon_{t}^2}{2h_{t}}} \\\\ \n",
    "    With \\space \\theta = (a_{0}, a_{1}, b_{1}) \\\\\\\\\n",
    "\\textbf{So the Log-Likelihood is} : \\\\\\\\\n",
    "    logL(\\theta) = -\\frac{1}{2} \\sum_{t=1}^{T} [log2\\pi + log h_{t} + \\frac{\\epsilon_{t}^2}{h_{t}}]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Log-Likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Logl(a_0,a_1,b_1,T):\n",
    "    L=[]\n",
    "    for t in range(2,T+1):\n",
    "        \n",
    "        Bi=[(b_1)**i for i in range(0,t)]    \n",
    "        \n",
    "        \n",
    "        Epsquare_t1i = Epsquare_t1[:len(Bi)].reshape(t,1)\n",
    "        \n",
    "        Bi=np.array(Bi).reshape(1,t)\n",
    "        \n",
    "        h_t= a_0*(1 - b_1**t)/(1-b_1) + a_1*np.dot(Bi,Epsquare_t1i)\n",
    "        \n",
    "        logl= np.log(2*np.pi) + np.log(h_t) + Epsquare_t1[t-1]/(h_t)\n",
    "        \n",
    "        L.append(logl)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return -(1/2)*np.sum(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.589034444064971"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_0,a_1,b_1=0.1,0.7,0.2\n",
    "Logl(a_0,a_1,b_1,T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First and Second derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_dev(f,x):\n",
    "    h1=0.0001\n",
    "    fx=f(x)\n",
    "    fxh1=f(x+h1)\n",
    "    \n",
    "    return (fxh1-fx)/h1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second_dev(f,x):\n",
    "    h2=0.0001\n",
    "    return (first_dev(f,x+h2) - first_dev(f,x))/h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0003000099987354"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dev(func,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.000599980410698"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_dev(func,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the optimal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the New Raphson algorithm to get successive local maximums :\n",
    "\n",
    "- Give initial guess to $\\theta_{0} = (a_{0}^0, a_{1}^0,b_{1}^0)$\n",
    "    \n",
    "- Getting a local maximum : \n",
    "   for instance for $a_{0}$, we can fix the values of $a_{1}$ and $b_{1}$ and compute its optimal value : $a_{0}^{new} = a_{0}^{old} - \\frac{\\partial logL(a_{0})}{\\partial a_{0}}|_{a_{0} = a_{0}^{old}} [\\frac{\\partial^2 logL(a_{0})}{\\partial a_{0}^2}|_{a_{0} = a_{0}^{old}}]^{-1}$\n",
    "   \n",
    "   After each iteration, we check the sign of $diff = logL(a_{0}^{new})-logL(a_{0}^{old})$. \n",
    "   * If diff > 0, then we update the value of $a_{0}$ to get a new value. NB : The last $a_{0}^{new}$ becomes the new $a_{0}^{old}$.\n",
    "   * If diff $\\leq$ 0, then we stop the iteration and retain the current $a_{0}^{old} = a_{0}^*$.\n",
    "- After getting the optimal value $a_{0}^*$, we use it to get the optimal value $a_{1}^*$ by the same process. And finally we use theses two optimal values to get the optimal value $b_{1}^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.589034444064971"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets' choose the initial values\n",
    "\n",
    "a0_0,a0_1,b0_1=0.1,0.7,0.2\n",
    "#Starting Log-likelihood\n",
    "Logl(a0_0,a0_1,b0_1,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb iter : 1; a_0 = 0.1; L1-L0 = 0.824\n",
      "Nb iter : 2; a_0 = 0.744; L1-L0 = 0.33\n",
      "Nb iter : 3; a_0 = 1.433; L1-L0 = 0.087\n",
      "Nb iter : 4; a_0 = 1.995; L1-L0 = 0.01\n",
      "Nb iter : 5; a_0 = 2.261; L1-L0 = 0.0\n",
      "Nb iter : 6; a_0 = 2.304; L1-L0 = 0.0\n",
      "Nb iter : 7; a_0 = 2.305; L1-L0 = 0.0\n",
      "Nb iter : 8; a_0 = 2.305; L1-L0 = -0.0\n"
     ]
    }
   ],
   "source": [
    "#Let's first optimize a_0\n",
    "\n",
    "#Here we fix a_1 = a0_1 and b_1 = b0_1 \n",
    "def Logl_a_0(a_0):\n",
    "    return Logl(a_0,a0_1,b0_1,T)\n",
    "\n",
    "a_0=a0_0\n",
    "nb_iter=0\n",
    "while True:\n",
    "    L0=Logl_a_0(a_0)\n",
    "\n",
    "    a1_0 = a_0 - first_dev(Logl_a_0,a_0)/second_dev(Logl_a_0,a_0)   #New value of a_0\n",
    "\n",
    "    L1=Logl_a_0(a1_0)   #New value of the log-likelihood\n",
    "    nb_iter+=1\n",
    "    \n",
    "    print(\"Nb iter : {}\".format(nb_iter),\"a_0 = {}\".format(round(a_0,3)),\"L1-L0 = {}\".format(round(L1-L0,3)),sep=\"; \")\n",
    "    if (L1-L0)<0:    #If the sign of the difference if negative\n",
    "        break        #Stop the iterating process\n",
    "    \n",
    "    a_0 = a1_0   # Otherwise, update the value of a_0\n",
    "\n",
    "a_0_opt = a_0     #Optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial value : 0.1\n",
      "Optimized value : 2.305\n"
     ]
    }
   ],
   "source": [
    "print(\"initial value : {}\".format(a0_0),\"Optimized value : {}\".format(round(a_0_opt,3)),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb iter : 1; a_1 = 0.7; L1-L0 = 0.0\n",
      "Nb iter : 2; a_1 = 0.702; L1-L0 = 0.0\n"
     ]
    }
   ],
   "source": [
    "#Let's  optimize a_1\n",
    "\n",
    "#Here we fix a_0 = a_0_opt and b_1 = b0_1 \n",
    "def Logl_a_1(a_1):\n",
    "    return Logl(a_0_opt,a_1,b0_1,T)\n",
    "\n",
    "a_1=a0_1\n",
    "nb_iter=0\n",
    "while nb_iter<10:\n",
    "    L0=Logl_a_1(a_1)\n",
    "\n",
    "    a1_1 = a_1 - first_dev(Logl_a_1,a_1)/second_dev(Logl_a_1,a_1)\n",
    "\n",
    "    L1=Logl_a_1(a1_1)   #New value of the log-likelihood\n",
    "    nb_iter+=1\n",
    "    \n",
    "    \n",
    "    if (L1-L0)<0:\n",
    "        break\n",
    "    \n",
    "    print(\"Nb iter : {}\".format(nb_iter),\"a_1 = {}\".format(round(a_1,3)),\"L1-L0 = {}\".format(round(L1-L0,3)),sep=\"; \")\n",
    "    a_1 = a1_1\n",
    "    \n",
    "a_1_opt = a_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial value : 0.7\n",
      "Optimized value : 0.702\n"
     ]
    }
   ],
   "source": [
    "print(\"initial value : {}\".format(a0_1),\"Optimized value : {}\".format(round(a_1_opt,3)),sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb iter : 1; b_1 = 0.2; L1-L0 = 0.0\n"
     ]
    }
   ],
   "source": [
    "#Let's first optimize b_1\n",
    "\n",
    "#Here we fix a_0 = a_0_opt and a_1 = a_1_opt  \n",
    "def Logl_b_1(b_1):\n",
    "    return Logl(a_0_opt,a_1_opt,b_1,T)\n",
    "\n",
    "b_1=b0_1\n",
    "nb_iter=0\n",
    "while nb_iter<10:\n",
    "    L0=Logl_b_1(b_1)\n",
    "\n",
    "    b1_1 = b_1 - first_dev(Logl_b_1,b_1)/second_dev(Logl_b_1,b_1)\n",
    "\n",
    "    L1=Logl_b_1(b1_1)   #New value of the log-likelihood\n",
    "    nb_iter+=1\n",
    "    \n",
    "    \n",
    "    if (L1-L0)<0:\n",
    "        break\n",
    "    \n",
    "    print(\"Nb iter : {}\".format(nb_iter),\"b_1 = {}\".format(round(b_1,3)),\"L1-L0 = {}\".format(round(L1-L0,3)),sep=\"; \")\n",
    "    \n",
    "    b_1 = b1_1\n",
    "    \n",
    "b_1_opt = b_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial value : 0.2\n",
      "Optimized value : 0.203\n"
     ]
    }
   ],
   "source": [
    "print(\"initial value : {}\".format(b0_1),\"Optimized value : {}\".format(round(b_1_opt,3)),sep=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
